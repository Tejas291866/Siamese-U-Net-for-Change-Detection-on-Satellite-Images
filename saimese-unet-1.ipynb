{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9898454,"sourceType":"datasetVersion","datasetId":6080252}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:15.846197Z","iopub.execute_input":"2024-12-20T07:01:15.846493Z","iopub.status.idle":"2024-12-20T07:01:18.765326Z","shell.execute_reply.started":"2024-12-20T07:01:15.846471Z","shell.execute_reply":"2024-12-20T07:01:18.764669Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ConvBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:18.766345Z","iopub.execute_input":"2024-12-20T07:01:18.766642Z","iopub.status.idle":"2024-12-20T07:01:18.771462Z","shell.execute_reply.started":"2024-12-20T07:01:18.766622Z","shell.execute_reply":"2024-12-20T07:01:18.770733Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class EncoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(EncoderBlock, self).__init__()\n        self.conv_block = ConvBlock(in_channels, out_channels)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        x = self.conv_block(x)\n        p = self.pool(x)\n        return x, p","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:18.773227Z","iopub.execute_input":"2024-12-20T07:01:18.773422Z","iopub.status.idle":"2024-12-20T07:01:18.792973Z","shell.execute_reply.started":"2024-12-20T07:01:18.773405Z","shell.execute_reply":"2024-12-20T07:01:18.792190Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class ConvLSTM(nn.Module):\n    def __init__(self, in_channels, hidden_channels, kernel_size, padding):\n        super(ConvLSTM, self).__init__()\n        self.conv = nn.Conv2d(in_channels + hidden_channels, 4 * hidden_channels, kernel_size, padding=padding)\n\n    def forward(self, x, hidden):\n        combined_input = torch.cat([x, hidden[0]], dim=1)\n        gates = self.conv(combined_input)\n        ingate, forgetgate, cellgate, outgate = torch.split(gates, gates.size(1) // 4, dim=1)\n        ingate = torch.sigmoid(ingate)\n        forgetgate = torch.sigmoid(forgetgate)\n        cellgate = torch.tanh(cellgate)\n        outgate = torch.sigmoid(outgate)\n        cell = forgetgate * hidden[1] + ingate * cellgate\n        hidden = outgate * torch.tanh(cell)\n        return hidden, cell","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:18.794231Z","iopub.execute_input":"2024-12-20T07:01:18.794517Z","iopub.status.idle":"2024-12-20T07:01:18.810612Z","shell.execute_reply.started":"2024-12-20T07:01:18.794488Z","shell.execute_reply":"2024-12-20T07:01:18.809951Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DecoderBlock, self).__init__()\n        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv_lstm = ConvLSTM(in_channels=out_channels, hidden_channels=out_channels, kernel_size=3, padding=1)\n\n    def forward(self, x, skip, hidden=None, cell=None):\n        x = self.up(x)\n        x = torch.cat([x, skip], dim=1)\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = F.relu(self.bn2(self.conv2(x)))\n        if hidden is not None and cell is not None:\n            x, _ = self.conv_lstm(x, (hidden, cell))\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:18.811463Z","iopub.execute_input":"2024-12-20T07:01:18.811739Z","iopub.status.idle":"2024-12-20T07:01:18.832801Z","shell.execute_reply.started":"2024-12-20T07:01:18.811712Z","shell.execute_reply":"2024-12-20T07:01:18.832088Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class AttentionBlock(nn.Module):\n    def __init__(self, F_g, F_l, F_int):\n        super(AttentionBlock, self).__init__()\n        self.W_g = nn.Sequential(\n            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.W_x = nn.Sequential(\n            nn.Conv2d(F_l, F_int, kernel_size=2, stride=2, padding=0, bias=True),\n            nn.BatchNorm2d(F_int)\n        )\n\n        self.psi = nn.Sequential(\n            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n            nn.BatchNorm2d(1),\n            nn.Sigmoid()\n        )\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, g, x):\n        g1 = self.W_g(g)\n        x1 = self.W_x(x)\n        psi = self.relu(g1 + x1)\n        psi = self.psi(psi)\n        psi = F.interpolate(psi, size=x.size()[2:], mode='bilinear', align_corners=True)\n        return x * psi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:18.833623Z","iopub.execute_input":"2024-12-20T07:01:18.833813Z","iopub.status.idle":"2024-12-20T07:01:18.848075Z","shell.execute_reply.started":"2024-12-20T07:01:18.833796Z","shell.execute_reply":"2024-12-20T07:01:18.847500Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class ASPPBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ASPPBlock, self).__init__()\n        self.conv1x1 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.conv3x3_1 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.conv3x3_2 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.conv3x3_3 = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=18, dilation=18, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.output_conv = nn.Sequential(\n            nn.Conv2d(out_channels * 4, out_channels, kernel_size=1, padding=0, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        x1 = self.conv1x1(x)\n        x2 = self.conv3x3_1(x)\n        x3 = self.conv3x3_2(x)\n        x4 = self.conv3x3_3(x)\n        x = torch.cat((x1, x2, x3, x4), dim=1)\n        x = self.output_conv(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:18.848825Z","iopub.execute_input":"2024-12-20T07:01:18.849035Z","iopub.status.idle":"2024-12-20T07:01:18.867390Z","shell.execute_reply.started":"2024-12-20T07:01:18.849016Z","shell.execute_reply":"2024-12-20T07:01:18.866659Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class SiameseUNet(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(SiameseUNet, self).__init__()\n        self.encoder1_1 = EncoderBlock(in_channels, 32)  \n        self.encoder1_2 = EncoderBlock(32, 64)          \n        self.encoder1_3 = EncoderBlock(64, 128)        \n        self.encoder1_4 = EncoderBlock(128, 256)        \n\n        self.encoder2_1 = EncoderBlock(in_channels, 32)  \n        self.encoder2_2 = EncoderBlock(32, 64)          \n        self.encoder2_3 = EncoderBlock(64, 128)         \n        self.encoder2_4 = EncoderBlock(128, 256)        \n\n        self.aspp = ASPPBlock(256 * 2, 512)             \n\n        self.attn1 = AttentionBlock(512, 256 * 2, 256)  \n        self.attn2 = AttentionBlock(256, 128 * 2, 128)  \n        self.attn3 = AttentionBlock(128, 64 * 2, 64)    \n        self.attn4 = AttentionBlock(64, 32 * 2, 32)     \n\n        self.decoder1 = DecoderBlock(512 + 512, 256)    \n        self.decoder2 = DecoderBlock(256 + 256, 128)    \n        self.decoder3 = DecoderBlock(128 + 128, 64)     \n        self.decoder4 = DecoderBlock(64 + 64, 32)       \n\n        self.final_conv = nn.Conv2d(32, out_channels, kernel_size=1)  # Assuming output channels remain 1\n\n    def forward(self, x1, x2):\n        # Encoder Path\n        s1_1, p1_1 = self.encoder1_1(x1)\n        s2_1, p2_1 = self.encoder1_2(p1_1)\n        s3_1, p3_1 = self.encoder1_3(p2_1)\n        s4_1, p4_1 = self.encoder1_4(p3_1)\n\n        s1_2, p1_2 = self.encoder2_1(x2)\n        s2_2, p2_2 = self.encoder2_2(p1_2)\n        s3_2, p3_2 = self.encoder2_3(p2_2)\n        s4_2, p4_2 = self.encoder2_4(p3_2)\n\n        # ASPP\n        concatenated = torch.cat((p4_1, p4_2), dim=1)\n        b1 = self.aspp(concatenated)\n\n        # Decoder Path with Attention\n        attn_s4 = self.attn1(b1, torch.cat((s4_1, s4_2), dim=1))\n        d1 = self.decoder1(b1, attn_s4)\n\n        attn_s3 = self.attn2(d1, torch.cat((s3_1, s3_2), dim=1))\n        d2 = self.decoder2(d1, attn_s3)\n\n        attn_s2 = self.attn3(d2, torch.cat((s2_1, s2_2), dim=1))\n        d3 = self.decoder3(d2, attn_s2)\n\n        attn_s1 = self.attn4(d3, torch.cat((s1_1, s1_2), dim=1))\n        d4 = self.decoder4(d3, attn_s1)\n\n        outputs = torch.sigmoid(self.final_conv(d4))\n        return outputs\n\n# Define the model\nmodel = SiameseUNet(in_channels=3, out_channels=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:18.868061Z","iopub.execute_input":"2024-12-20T07:01:18.868403Z","iopub.status.idle":"2024-12-20T07:01:19.114490Z","shell.execute_reply.started":"2024-12-20T07:01:18.868379Z","shell.execute_reply":"2024-12-20T07:01:19.113771Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\nclass CustomWHUDataset(Dataset):\n    def __init__(self, base_dir, image_list_file, transform=None):\n        self.base_dir = base_dir\n        self.image_list_file = image_list_file\n        self.transform = transform\n\n        # Read the file containing image names\n        with open(image_list_file, 'r') as f:\n            self.image_names = [line.strip() for line in f.readlines()]\n\n    def __len__(self):\n        return len(self.image_names)\n\n    def __getitem__(self, idx):\n        # Get the image name from the list\n        image_name = self.image_names[idx]\n\n        # Construct the full paths for time1, time2, and label images\n        time1_path = os.path.join(self.base_dir, 'A', f\"{image_name}\")\n        time2_path = os.path.join(self.base_dir, 'B', f\"{image_name}\")\n        label_path = os.path.join(self.base_dir, 'label', f\"{image_name}\")\n\n        # Open the images\n        time1_image = Image.open(time1_path).convert('RGB')\n        time2_image = Image.open(time2_path).convert('RGB')\n        label_image = Image.open(label_path).convert('L')\n\n        # Apply transformations if provided\n        if self.transform:\n            time1_image = self.transform(time1_image)\n            time2_image = self.transform(time2_image)\n            label_image = self.transform(label_image)\n\n        return (time1_image, time2_image), label_image\n\n# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])\n\n# Define base directory and list files\nbase_dir = '/kaggle/input/whu-rs-change-dataset'\ntrain_list_file = os.path.join(base_dir, 'list', 'train.txt')\nval_list_file = os.path.join(base_dir, 'list', 'val.txt')\ntest_list_file = os.path.join(base_dir, 'list', 'test.txt')\n\n# Create Dataset instances\ntrain_dataset = CustomWHUDataset(base_dir, train_list_file, transform=transform)\nval_dataset = CustomWHUDataset(base_dir, val_list_file, transform=transform)\ntest_dataset = CustomWHUDataset(base_dir, test_list_file, transform=transform)\n\n# Create DataLoader instances\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:19.116698Z","iopub.execute_input":"2024-12-20T07:01:19.116948Z","iopub.status.idle":"2024-12-20T07:01:20.283313Z","shell.execute_reply.started":"2024-12-20T07:01:19.116927Z","shell.execute_reply":"2024-12-20T07:01:20.282606Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch.optim as optim\n# Initialize the  loss function, and optimizer\n\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-5)\n\n# Define device (GPU/CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:20.284433Z","iopub.execute_input":"2024-12-20T07:01:20.284739Z","iopub.status.idle":"2024-12-20T07:01:20.555347Z","shell.execute_reply.started":"2024-12-20T07:01:20.284707Z","shell.execute_reply":"2024-12-20T07:01:20.554613Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"SiameseUNet(\n  (encoder1_1): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_2): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_3): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_4): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_1): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_2): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_3): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_4): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (aspp): ASPPBlock(\n    (conv1x1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_2): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_3): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (output_conv): Sequential(\n      (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (attn1): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn2): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn3): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn4): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (decoder1): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder2): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder3): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder4): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def save_checkpoint(state, filename='model_checkpoint.pth.tar'):\n    print('=>saving')\n    torch.save(state, filename)\n\n# Function to load the model checkpoint\ndef load_checkpoint(filename='model_checkpoint.pth.tar', model=None, optimizer=None):\n    if os.path.isfile(filename):\n        print(f\"Loading checkpoint '{filename}'\")\n        checkpoint = torch.load(filename)\n        if model is not None:\n            model.load_state_dict(checkpoint['state_dict'])\n        if optimizer is not None:\n            optimizer.load_state_dict(checkpoint['optimizer'])\n        return checkpoint\n    else:\n        print(f\"No checkpoint found at '{filename}'\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:20.556038Z","iopub.execute_input":"2024-12-20T07:01:20.556252Z","iopub.status.idle":"2024-12-20T07:01:20.561333Z","shell.execute_reply.started":"2024-12-20T07:01:20.556234Z","shell.execute_reply":"2024-12-20T07:01:20.560265Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, model_save_path):\n    best_loss = float('inf')\n    patience_counter = 0\n    start_epoch = 0\n\n    # Load checkpoint if it exists\n    checkpoint = load_checkpoint(model_save_path, model, optimizer)\n    if checkpoint:\n        start_epoch = checkpoint.get('epoch', 0) + 1\n        best_loss = checkpoint.get('best_loss', float('inf'))\n\n    for epoch in range(start_epoch, num_epochs):\n        model.train()\n        train_losses = []\n\n        for (time1_image, time2_image), target in train_loader:\n            time1_image, time2_image, target = time1_image.to(device), time2_image.to(device), target.to(device)\n\n            optimizer.zero_grad()\n            output = model(time1_image, time2_image)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n            train_losses.append(loss.item())\n\n        val_loss = evaluate(model, val_loader, criterion)\n        print(f'Epoch {epoch+1}, Train Loss: {np.mean(train_losses):.4f}, Val Loss: {val_loss:.4f}')\n\n        if val_loss < best_loss:\n            best_loss = val_loss\n            patience_counter = 0\n            save_checkpoint({\n                'epoch': epoch,\n                'state_dict': model.state_dict(),\n                'optimizer': optimizer.state_dict(),\n                'best_loss': best_loss\n            }, model_save_path)\n        else:\n            patience_counter += 1\n\n        if patience_counter >= patience:\n            print(\"Early stopping\")\n            break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:20.562121Z","iopub.execute_input":"2024-12-20T07:01:20.562407Z","iopub.status.idle":"2024-12-20T07:01:20.577362Z","shell.execute_reply.started":"2024-12-20T07:01:20.562380Z","shell.execute_reply":"2024-12-20T07:01:20.576661Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Function to evaluate the model\ndef evaluate(model, val_loader, criterion):\n    model.eval()\n    val_losses = []\n    with torch.no_grad():\n        for (time1, time2), target in val_loader:\n            time1, time2, target = time1.to(device), time2.to(device), target.to(device)\n            output = model(time1, time2)\n            loss = criterion(output, target)\n            val_losses.append(loss.item())\n    return np.mean(val_losses)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:20.578096Z","iopub.execute_input":"2024-12-20T07:01:20.578320Z","iopub.status.idle":"2024-12-20T07:01:20.596071Z","shell.execute_reply.started":"2024-12-20T07:01:20.578301Z","shell.execute_reply":"2024-12-20T07:01:20.595208Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Function to count the number of parameters\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters())\n\n# Function to count the number of trainable parameters\ndef count_trainable_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# Print the number of parameters\ntotal_params = count_parameters(model)\ntrainable_params = count_trainable_parameters(model)\nprint(f\"Total parameters: {total_params}\")\nprint(f\"Trainable parameters: {trainable_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:20.596813Z","iopub.execute_input":"2024-12-20T07:01:20.597084Z","iopub.status.idle":"2024-12-20T07:01:20.613469Z","shell.execute_reply.started":"2024-12-20T07:01:20.597064Z","shell.execute_reply":"2024-12-20T07:01:20.612848Z"}},"outputs":[{"name":"stdout","text":"Total parameters: 21804365\nTrainable parameters: 21804365\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Model path\nmodel_save_path = '/kaggle/working/siamese_unet_best_model.pth'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:20.614287Z","iopub.execute_input":"2024-12-20T07:01:20.614481Z","iopub.status.idle":"2024-12-20T07:01:20.632248Z","shell.execute_reply.started":"2024-12-20T07:01:20.614464Z","shell.execute_reply":"2024-12-20T07:01:20.631546Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, patience=3, model_save_path=model_save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:01:20.632985Z","iopub.execute_input":"2024-12-20T07:01:20.633245Z","iopub.status.idle":"2024-12-20T07:39:02.838873Z","shell.execute_reply.started":"2024-12-20T07:01:20.633220Z","shell.execute_reply":"2024-12-20T07:39:02.837826Z"}},"outputs":[{"name":"stdout","text":"No checkpoint found at '/kaggle/working/siamese_unet_best_model.pth'\nEpoch 1, Train Loss: 0.5735, Val Loss: 0.4955\n=>saving\nEpoch 2, Train Loss: 0.4452, Val Loss: 0.4247\n=>saving\nEpoch 3, Train Loss: 0.4132, Val Loss: 0.4194\n=>saving\nEpoch 4, Train Loss: 0.4014, Val Loss: 0.3931\n=>saving\nEpoch 5, Train Loss: 0.3887, Val Loss: 0.3820\n=>saving\nEpoch 6, Train Loss: 0.3811, Val Loss: 0.4240\nEpoch 7, Train Loss: 0.3764, Val Loss: 0.3635\n=>saving\nEpoch 8, Train Loss: 0.3646, Val Loss: 0.3572\n=>saving\nEpoch 9, Train Loss: 0.3597, Val Loss: 0.4892\nEpoch 10, Train Loss: 0.3549, Val Loss: 0.3536\n=>saving\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Load the best model\nload_checkpoint(model_save_path, model, optimizer)\n\n# Evaluate on the validation set\nval_loss = evaluate(model, val_loader, criterion)\nprint(\"Validation Loss:\", val_loss)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:39:02.840285Z","iopub.execute_input":"2024-12-20T07:39:02.840699Z","iopub.status.idle":"2024-12-20T07:39:14.315389Z","shell.execute_reply.started":"2024-12-20T07:39:02.840660Z","shell.execute_reply":"2024-12-20T07:39:14.314347Z"}},"outputs":[{"name":"stdout","text":"Loading checkpoint '/kaggle/working/siamese_unet_best_model.pth'\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-12-9915653e5d8e>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(filename)\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.35364921887715656\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n\ndef calculate_metrics(y_true, y_pred, threshold=0.5):\n    y_pred = (y_pred > threshold).float()\n    \n    y_true_np = y_true.cpu().numpy().flatten()\n    y_pred_np = y_pred.cpu().numpy().flatten()\n    \n    accuracy = accuracy_score(y_true_np, y_pred_np)\n    precision = precision_score(y_true_np, y_pred_np, average='binary', zero_division=1)\n    recall = recall_score(y_true_np, y_pred_np, average='binary', zero_division=1)\n    f1 = f1_score(y_true_np, y_pred_np, average='binary', zero_division=1)\n    iou = jaccard_score(y_true_np, y_pred_np, average='binary', zero_division=1)\n    \n    return accuracy, precision, recall, f1, iou\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:39:14.316305Z","iopub.execute_input":"2024-12-20T07:39:14.316623Z","iopub.status.idle":"2024-12-20T07:39:14.885825Z","shell.execute_reply.started":"2024-12-20T07:39:14.316591Z","shell.execute_reply":"2024-12-20T07:39:14.884936Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def test_metric_model(model, test_loader, criterion, device):\n    model.eval()\n    test_loss = 0.0\n    all_true = []\n    all_pred = []\n    \n    with torch.no_grad():\n        for (time1, time2), target in test_loader:\n            time1, time2, target = time1.to(device), time2.to(device), target.to(device)\n            output = model(time1, time2)\n            loss = criterion(output, target)\n            test_loss += loss.item()\n\n            all_true.append(target)\n            all_pred.append(output)\n    \n    # Concatenate all batches\n    all_true = torch.cat(all_true, dim=0)\n    all_pred = torch.cat(all_pred, dim=0)\n    \n    # Calculate metrics\n    accuracy, precision, recall, f1, iou = calculate_metrics(all_true, all_pred)\n    \n    return test_loss / len(test_loader), accuracy, precision, recall, f1, iou\n\n# Assuming model, test_loader, criterion, and device are defined as in your code\ntest_loss, accuracy, precision, recall, f1, iou = test_metric_model(model, test_loader, criterion, device)\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Accuracy: {accuracy:.4f}')\nprint(f'Precision: {precision:.4f}')\nprint(f'Recall: {recall:.4f}')\nprint(f'F1 Score: {f1:.4f}')\nprint(f'IoU: {iou:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:39:14.886805Z","iopub.execute_input":"2024-12-20T07:39:14.887169Z","iopub.status.idle":"2024-12-20T07:42:40.169278Z","shell.execute_reply.started":"2024-12-20T07:39:14.887137Z","shell.execute_reply":"2024-12-20T07:42:40.168551Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.3526\nAccuracy: 0.9848\nPrecision: 0.8116\nRecall: 0.7964\nF1 Score: 0.8039\nIoU: 0.6721\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom torch.utils.data import DataLoader\n\ndef calculate_iou(predictions, labels):\n    intersection = np.logical_and(predictions, labels).sum()\n    union = np.logical_or(predictions, labels).sum()\n    iou = intersection / union if union != 0 else 0\n    return iou\n\n\nload_checkpoint(model_save_path, model, optimizer=None)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Initialize lists to store evaluation results\naccuracies = []\nprecisions = []\nrecalls = []\nf1_scores = []\nious=[]\n\n# Ensure no gradients are computed during evaluation\nwith torch.no_grad():\n    # Iterate through the test dataloader\n    for (time1_image, time2_image), labels in test_loader:\n        # Convert inputs and labels to PyTorch tensors and move to the appropriate device\n        time1_image = time1_image.to(device)\n        time2_image = time2_image.to(device)\n        labels = labels.to(device)\n        \n        # Forward pass\n        outputs = model(time1_image, time2_image)\n        \n        # Convert outputs to binary predictions\n        predictions = (outputs > 0.5).float()\n        \n        # Ensure the predictions are binary\n        predictions_np = predictions.cpu().detach().numpy().astype(int)\n        labels_np = labels.cpu().detach().numpy().astype(int)\n        \n        # Flatten arrays for sklearn metrics\n        predictions_flat = predictions_np.flatten()\n        labels_flat = labels_np.flatten()\n        \n        # Calculate metrics\n        accuracy = accuracy_score(labels_flat, predictions_flat)\n        precision = precision_score(labels_flat, predictions_flat, zero_division=1)\n        recall = recall_score(labels_flat, predictions_flat, zero_division=1)\n        f1 = f1_score(labels_flat, predictions_flat, zero_division=1)\n        \n        iou = calculate_iou(predictions_np, labels_np)\n        \n        # Append results to lists\n        accuracies.append(accuracy)\n        precisions.append(precision)\n        recalls.append(recall)\n        f1_scores.append(f1)\n        ious.append(iou)\n\n# Calculate average metrics\navg_accuracy = np.mean(accuracies)\navg_precision = np.mean(precisions)\navg_recall = np.mean(recalls)\navg_f1 = np.mean(f1_scores)\navg_iou = np.mean(ious)\n\nprint(\"Average Accuracy:\", avg_accuracy)\nprint(\"Average Precision:\", avg_precision)\nprint(\"Average Recall:\", avg_recall)\nprint(\"Average F1 Score:\", avg_f1)\nprint(\"Average IoU:\", avg_iou)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:42:40.170136Z","iopub.execute_input":"2024-12-20T07:42:40.170385Z","iopub.status.idle":"2024-12-20T07:44:59.114247Z","shell.execute_reply.started":"2024-12-20T07:42:40.170364Z","shell.execute_reply":"2024-12-20T07:44:59.113281Z"}},"outputs":[{"name":"stdout","text":"Loading checkpoint '/kaggle/working/siamese_unet_best_model.pth'\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-12-9915653e5d8e>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(filename)\n","output_type":"stream"},{"name":"stdout","text":"Average Accuracy: 0.9847684237692093\nAverage Precision: 0.792368304563508\nAverage Recall: 0.7846505879993385\nAverage F1 Score: 0.7796273625231404\nAverage IoU: 0.65201917684659\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\n# Assuming SiameseUNet and related classes are defined as in your provided code\n# Define the model\nmodel = SiameseUNet(in_channels=3, out_channels=1)\n\n# Load the model checkpoint\nmodel_save_path = '/kaggle/working/siamese_unet_best_model.pth'\nload_checkpoint(model_save_path, model, optimizer=None)\n\n# Set the model to evaluation mode\nmodel.eval()\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:44:59.115205Z","iopub.execute_input":"2024-12-20T07:44:59.115543Z","iopub.status.idle":"2024-12-20T07:44:59.533079Z","shell.execute_reply.started":"2024-12-20T07:44:59.115511Z","shell.execute_reply":"2024-12-20T07:44:59.532160Z"}},"outputs":[{"name":"stdout","text":"Loading checkpoint '/kaggle/working/siamese_unet_best_model.pth'\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-12-9915653e5d8e>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(filename)\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"SiameseUNet(\n  (encoder1_1): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_2): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_3): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder1_4): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_1): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_2): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_3): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (encoder2_4): EncoderBlock(\n    (conv_block): ConvBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (aspp): ASPPBlock(\n    (conv1x1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_1): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_2): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (conv3x3_3): Sequential(\n      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (output_conv): Sequential(\n      (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (attn1): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn2): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn3): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (attn4): AttentionBlock(\n    (W_g): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (decoder1): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder2): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder3): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (decoder4): DecoderBlock(\n    (up): Upsample(scale_factor=2.0, mode='bilinear')\n    (conv1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (conv_lstm): ConvLSTM(\n      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    )\n  )\n  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"import torchvision.transforms as transforms\n# Define the transformations (resize and convert to tensor)\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:44:59.534045Z","iopub.execute_input":"2024-12-20T07:44:59.534366Z","iopub.status.idle":"2024-12-20T07:44:59.538226Z","shell.execute_reply.started":"2024-12-20T07:44:59.534331Z","shell.execute_reply":"2024-12-20T07:44:59.537322Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from PIL import Image\n\n\n# Load the images\ndef load_image(image_path, transform):\n    image = Image.open(image_path).convert('RGB')\n    image = transform(image)\n    image = image.unsqueeze(0)  # Add batch dimension\n    return image.to(device)\n\n# Example image paths\ntime1_image_path = '/kaggle/input/whu-rs-change-dataset/A/whu_12544_32256.png'\ntime2_image_path = '/kaggle/input/whu-rs-change-dataset/B/whu_12544_32256.png'\nlabel_image_path='/kaggle/input/whu-rs-change-dataset/label/whu_12544_32256.png'\n# Preprocess the images\ntime1_image = load_image(time1_image_path, transform)\ntime2_image = load_image(time2_image_path, transform)\nlabel_image=load_image(label_image_path, transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:44:59.539204Z","iopub.execute_input":"2024-12-20T07:44:59.539511Z","iopub.status.idle":"2024-12-20T07:44:59.572242Z","shell.execute_reply.started":"2024-12-20T07:44:59.539480Z","shell.execute_reply":"2024-12-20T07:44:59.571489Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Make predictions\nwith torch.no_grad():\n    output = model(time1_image, time2_image)\n\n# Convert the output to a binary mask (if required)\nprediction = (output > 0.5).float()\n\n# To convert the tensor to a numpy array (for further processing or saving the output image)\nprediction_np = prediction.squeeze().cpu().numpy()\n\n# Optionally, save the output prediction as an image\nimport numpy as np\nfrom PIL import Image\n\nprediction_image = Image.fromarray((prediction_np * 255).astype(np.uint8))\nprediction_image.save('/kaggle/working/prediction_image00878.png')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T07:44:59.572965Z","iopub.execute_input":"2024-12-20T07:44:59.573172Z","iopub.status.idle":"2024-12-20T07:44:59.626563Z","shell.execute_reply.started":"2024-12-20T07:44:59.573153Z","shell.execute_reply":"2024-12-20T07:44:59.625867Z"}},"outputs":[],"execution_count":25}]}